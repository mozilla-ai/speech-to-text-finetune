{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Speech-to-Text Finetune Blueprint","text":"<p>Blueprints empower developers to easily integrate AI capabilities into their projects using open-source models and tools.</p> <p>These docs are your companion to mastering the Speech-to-Text Finetune Blueprint \u2014a local-friendly approach for finetuning an STT model on your own data or on CommonVoice data.</p>"},{"location":"#built-with","title":"Built with","text":""},{"location":"#get-started-quickly","title":"\ud83d\ude80 Get Started Quickly","text":""},{"location":"#start-transcribing-with-huggingface-models-or-finetune-your-own-custom-stt-models-in-minutes","title":"Start transcribing with HuggingFace models or finetune your own custom STT models in minutes:","text":"<ul> <li>Getting Started: Quick setup and installation instructions.</li> </ul>"},{"location":"#understand-the-system","title":"\ud83d\udd0d Understand the System","text":""},{"location":"#dive-deeper-into-how-the-blueprint-works","title":"Dive deeper into how the Blueprint works:","text":"<ul> <li>Step-by-Step Guide: A detailed breakdown of how to use the Blueprint with a suggested user-flow.</li> <li>API Reference: Explore the technical details of the core modules.</li> </ul>"},{"location":"#make-it-yours","title":"\ud83c\udfa8 Make It Yours","text":""},{"location":"#customize-the-blueprint-to-fit-your-needs","title":"Customize the Blueprint to fit your needs:","text":"<ul> <li>Customization Guide: Coming Soon</li> </ul>"},{"location":"#join-the-community","title":"\ud83c\udf1f Join the Community","text":""},{"location":"#help-shape-the-future-of-blueprints","title":"Help shape the future of Blueprints:","text":"<ul> <li>Future Features &amp; Contributions: Learn about exciting upcoming features and how to contribute to the project.</li> </ul> <p>Have more questions? Reach out to us on Discord and we'll see how we can help:</p> <p></p>"},{"location":"api/","title":"API Reference","text":"<p>\"::: speech_to_text_finetune.config\" \"::: speech_to_text_finetune.data_process\" \"::: speech_to_text_finetune.finetune_whisper\" \"::: speech_to_text_finetune.hf_utils\" \"::: speech_to_text_finetune.make_local_dataset_app\"</p>"},{"location":"customization/","title":"\ud83c\udfa8 Customization Guide","text":"<p>This Blueprint is designed to be flexible and easily adaptable to your specific needs. This guide will walk you through some key areas you can customize to make the Blueprint your own.</p>"},{"location":"customization/#customization-guide-coming-soon","title":"Customization Guide Coming Soon","text":""},{"location":"customization/#contributing-to-the-blueprint","title":"\ud83e\udd1d Contributing to the Blueprint","text":"<p>Want to help improve or extend this Blueprint? Check out the Future Features &amp; Contributions Guide to see how you can contribute your ideas, code, or feedback to make this Blueprint even better!</p>"},{"location":"future-features-contributions/","title":"\ud83d\ude80 Future Features &amp; Contributions","text":"<p>This Blueprint is an evolving project designed to grow with the help of the open-source community. Whether you\u2019re an experienced developer or just starting, there are many ways you can contribute and help shape the future of this tool.</p>"},{"location":"future-features-contributions/#how-you-can-contribute","title":"\ud83c\udf1f How You Can Contribute","text":""},{"location":"future-features-contributions/#enhance-the-blueprint","title":"\ud83d\udee0\ufe0f Enhance the Blueprint","text":"<ul> <li>Check the Issues page to see if there are feature requests you'd like to implement</li> <li>Refer to our Contribution Guide for more details on contributions</li> </ul>"},{"location":"future-features-contributions/#extensibility-ideas","title":"\ud83c\udfa8 Extensibility Ideas","text":"<p>This Blueprint is designed to be a foundation you can build upon. By extending its capabilities, you can open the door to new applications, improve user experience, and adapt the Blueprint to address other use cases. Here are a few ideas for how you can expand its potential: - Add support for more types of models to finetune, such as w2v2-bert. More info here - Improve the training efficiency and speed using PEFT + LORA. More info here</p> <p>We\u2019d love to see how you can enhance this Blueprint! If you create improvements or extend its capabilities, consider contributing them back to the project so others in the community can benefit from your work. Check out our Contributions Guide to get started!</p>"},{"location":"future-features-contributions/#share-your-ideas","title":"\ud83d\udca1 Share Your Ideas","text":"<p>Got an idea for how this Blueprint could be improved? You can share your suggestions through GitHub Discussions.</p>"},{"location":"future-features-contributions/#build-new-blueprints","title":"\ud83c\udf0d Build New Blueprints","text":"<p>This project is part of a larger initiative to create a collection of reusable starter code solutions that use open-source AI tools. If you\u2019re inspired to create your own Blueprint, you can use the Blueprint-template to get started.</p> <p>Your contributions help make this Blueprint better for everyone \ud83c\udf89</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#get-started-with-speech-to-text-finetune-blueprint-using-one-of-the-options-below","title":"Get started with Speech-to-text-finetune Blueprint using one of the options below:","text":""},{"location":"getting-started/#setup-options","title":"Setup options","text":"\u2601\ufe0f Google Colab (GPU)\u2601\ufe0f GitHub Codespaces\ud83d\udcbb Local Installation <p>Finetune a STT model using CommonVoice data by launching the Google Colab notebook below</p> <p>Click the button below to launch the project directly in Google Colab:</p> <p><p></p></p> <p>Click the button below to launch the project directly in GitHub Codespaces:</p> <p><p></p></p> <p>Once the Codespaces environment launches, inside the terminal, install dependencies:</p> <pre><code>pip install -e .\n</code></pre> <p>To load the app for making your own dataset for STT finetuning:</p> <pre><code>python src/speech_to_text_finetune/make_local_dataset_app.py\n</code></pre> <p>To load the Transcription app:</p> <pre><code>python demo/transcribe_app.py\n</code></pre> <p>To run the Finetuning job:</p> <pre><code>python src/speech_to_text_finetune/finetune_whisper.py\n</code></pre> <p>To install the project locally:</p> <pre><code>git clone https://github.com/mozilla-ai/speech-to-text-finetune.git\ncd speech-to-text-finetune\n</code></pre> <p>install dependencies:</p> <pre><code>pip install -e .\n</code></pre> <p>To load the app for making your own dataset for STT finetuning:</p> <pre><code>python src/speech_to_text_finetune/make_local_dataset_app.py\n</code></pre> <p>To load the Transcription app:</p> <pre><code>python demo/transcribe_app.py\n</code></pre> <p>To run the Finetuning job:</p> <pre><code>python src/speech_to_text_finetune/finetune_whisper.py\n</code></pre>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":"<p>Troubleshooting - TBA</p>"},{"location":"step-by-step-guide/","title":"Step-by-Step Guide: How the Speech-to-Text-Finetune Blueprint Works","text":"<p>This Blueprint enables you to fine-tune a Speech-to-Text (STT) model, using either your own data or the Common Voice dataset. This Step-by-Step guide you through the end-to-end process of finetuning an STT model based on your needs.</p>"},{"location":"step-by-step-guide/#overview","title":"Overview","text":"<p>This blueprint consists of three independent, yet complementary, components:</p> <ol> <li> <p>Transcription app \ud83c\udf99\ufe0f\ud83d\udcdd: A simple UI that lets you record your voice, pick any HF STT/ASR model, and get an instant transcription.</p> </li> <li> <p>Dataset maker app \ud83d\udcc2\ud83c\udfa4: Another UI app that enables you to easily and quickly create your own Speech-to-Text dataset.</p> </li> <li> <p>Finetuning script \ud83d\udee0\ufe0f\ud83e\udd16: A script to finetune your own STT model, either using Common Voice data or your own local data created by the Dataset maker app.</p> </li> </ol>"},{"location":"step-by-step-guide/#step-by-step-guide","title":"Step-by-Step Guide","text":"<p>Visit the Getting Started page for the initial project setup.</p> <p>The following guide is a suggested user-flow for getting the most out of this Blueprint</p>"},{"location":"step-by-step-guide/#step-1-initial-transcription-testing","title":"Step 1 - Initial transcription testing","text":"<p>Start by initially testing the quality of the Speech-to-Text models available in HuggingFace:</p> <ol> <li> <p>Simply execute:</p> <pre><code>python demo/transcribe_app.py\n</code></pre> </li> <li> <p>Select or add the HF model id of your choice</p> </li> <li>Record a sample of your voice and get the transcribed text back. You may find that there are sometimes inaccuracies for your voice/accent/chosen language, indicating the model could benefit form finetuning on additional data.</li> </ol>"},{"location":"step-by-step-guide/#step-2-make-your-local-dataset-for-stt-finetuning","title":"Step 2 - Make your Local Dataset for STT finetuning","text":"<ol> <li> <p>Create your own, local dataset by running this command and following the instructions:</p> <pre><code>python src/speech_to_text_finetune/make_local_dataset_app.py\n</code></pre> </li> <li> <p>Follow the instruction in the app to create at least 10 audio samples, which will be saved locally.</p> </li> </ol>"},{"location":"step-by-step-guide/#step-3-creating-a-finetuned-stt-model-using-your-local-data","title":"Step 3 - Creating a finetuned STT model using your local data","text":"<ol> <li> <p>Configure <code>config.yaml</code> with the model, local data directory and hyperparameters of your choice. Note that if you select <code>push_to_hub: True</code> you need to have an HF account and log in locally. For example:</p> <pre><code>model_id: openai/whisper-tiny\ndataset_id: example_data/custom\ndataset_source: local\nlanguage: English\nrepo_name: default\n\ntraining_hp:\n    push_to_hub: False\n    hub_private_repo: True\n    ...\n</code></pre> </li> <li> <p>Finetune a model by running: <pre><code>python src/speech_to_text_finetune/finetune_whisper.py\n</code></pre></p> </li> </ol>"},{"location":"step-by-step-guide/#step-4-optional-creating-a-finetuned-stt-model-using-commonvoice-data","title":"Step 4 - (Optional) Creating a finetuned STT model using CommonVoice data","text":"<p>Note: A Hugging Face account is required!</p> <ol> <li>Go to the Common Voice dataset repo and ask for explicit access request (should be approved instantly).</li> <li>On Hugging Face create an Access Token</li> <li>In your terminal, run the command <code>huggingface-cli login</code> and follow the instructions to log in to your account.</li> <li>Configure <code>config.yaml</code> with the model, Common Voice dataset repo id of HF and hyperparameters of your choice. For example: <pre><code>model_id = \"openai/whisper-tiny\"\ndataset_id = \"mozilla-foundation/common_voice_17_0\"\nlanguage = \"Greek\"\nrepo_name: default\n\ntraining_hp:\n    push_to_hub: False\n    hub_private_repo: True\n    ...\n</code></pre></li> <li>Finetune a model by running: <pre><code>python src/speech_to_text_finetune/finetune_whisper.py\n</code></pre></li> </ol>"},{"location":"step-by-step-guide/#step-5-evaluate-transcription-accuracy-with-your-finetuned-stt-model","title":"Step 5 - Evaluate transcription accuracy with your finetuned STT model","text":"<ol> <li>Start the Transcription app:  <code>bash python demo/transcribe_app.py</code></li> <li>Provided that <code>push_to_hub: True</code> when you Finetuned, you can select your HuggingFace model-id. If not, you can specify the local path to your model</li> <li>Record a sample of your voice and get the transcribed text back.</li> <li>You can easily switch between models with the same recorded sample to evaluate if the finetuned model has improved transcription accuracy.</li> </ol>"},{"location":"step-by-step-guide/#customizing-the-blueprint","title":"\ud83c\udfa8 Customizing the Blueprint","text":"<p>To better understand how you can tailor this Blueprint to suit your specific needs, please visit the Customization Guide.</p>"},{"location":"step-by-step-guide/#contributing-to-the-blueprint","title":"\ud83e\udd1d Contributing to the Blueprint","text":"<p>Want to help improve or extend this Blueprint? Check out the Future Features &amp; Contributions Guide to see how you can contribute your ideas, code, or feedback to make this Blueprint even better!</p>"},{"location":"step-by-step-guide/#resources-references","title":"\ud83d\udcd6 Resources &amp; References","text":"<p>If you are interested in learning more about this topic, you might find the following resources helpful: - Fine-Tune Whisper For Multilingual ASR with \ud83e\udd17 Transformers (Blog post by HuggingFace which inspired the implementation of the Blueprint!)</p> <ul> <li> <p>Automatic Speech Recognition Course from HuggingFace (Series of Blog posts)</p> </li> <li> <p>Fine-Tuning ASR Models: Key Definitions, Mechanics, and Use Cases (Blog post by Gladia)</p> </li> <li> <p>Active Learning Approach for Fine-Tuning Pre-Trained ASR Model for a low-resourced Language (Paper)</p> </li> <li> <p>Exploration of Whisper fine-tuning strategies for low-resource ASR (Paper)</p> </li> <li> <p>Finetuning Pretrained Model with Embedding of Domain and Language Information for ASR of Very Low-Resource Settings (Paper)</p> </li> </ul>"}]}